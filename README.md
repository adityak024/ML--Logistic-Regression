ğŸ§  Logistic Regression in Python â€“ Classification Techniques & Evaluation
This repository explores Logistic Regression, one of the most widely used classification algorithms in machine learning. Through hands-on Python implementations, we apply logistic regression in various real-world scenarios including binary, multiclass, and imbalanced data classifications.

ğŸ—‚ï¸ Contents
ğŸ“˜ Introduction to Logistic Regression

ğŸ“Š Dataset Handling & Preprocessing

ğŸ§ª Model Training and Evaluation

ğŸ” Hyperparameter Tuning

ğŸ”„ Cross-Validation

âš–ï¸ Handling Imbalanced Data

ğŸ“ˆ Visualization & Metrics

ğŸ’¾ Model Saving & Loading

ğŸ“Œ Key Learning Outcomes
Apply logistic regression for binary and multiclass classification

Perform regularization: L1 (Lasso), L2 (Ridge), and ElasticNet

Evaluate models using accuracy, precision, recall, F1, ROC-AUC, MCC, Cohenâ€™s Kappa

Implement hyperparameter tuning with GridSearchCV and RandomizedSearchCV

Use feature scaling and analyze its impact

Visualize confusion matrix and PR curve

Handle imbalanced datasets with class weights

Save and load models using joblib

ğŸ”§ Python Practice Tasks Included
ğŸ”¹ Basic Logistic Regression
âœ… Train-Test Split & Accuracy
Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.

âœ… Load from CSV & Evaluate
Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.

ğŸ”¹ Regularization Techniques
ğŸ”’ L1 Regularization (Lasso)
LogisticRegression(penalty='l1', solver='liblinear')

ğŸ” L2 Regularization (Ridge)
LogisticRegression(penalty='l2')
â†’ Print model coefficients & accuracy

ğŸ” Elastic Net Regularization
LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga')

ğŸ”¹ Multiclass Classification
ğŸ¯ One-vs-Rest (OvR)
LogisticRegression(multi_class='ovr')

âš”ï¸ One-vs-One (OvO)
Using OneVsOneClassifier(LogisticRegression()) from sklearn.multiclass

ğŸ”¹ Hyperparameter Tuning
ğŸ” GridSearchCV for Logistic Regression
Tune C and penalty, print best parameters and accuracy.

ğŸ² RandomizedSearchCV for tuning C, penalty, and solver
â†’ Save computation time vs exhaustive grid search

ğŸ”¹ Model Evaluation Techniques
ğŸ”„ Stratified K-Fold Cross-Validation
â†’ Print average accuracy across folds

ğŸ“‰ Precision, Recall, F1-Score Evaluation

ğŸ“Š Confusion Matrix Visualization
â†’ Use seaborn.heatmap or ConfusionMatrixDisplay

ğŸ“ˆ ROC-AUC Score

ğŸ“ Cohenâ€™s Kappa Score

ğŸ“Š Matthews Correlation Coefficient (MCC)

ğŸ”¹ Advanced Use Cases
âš–ï¸ Class Weights for Imbalanced Data
LogisticRegression(class_weight='balanced')

ğŸ“ Custom Regularization Strength (C=0.5)
â†’ Observe model flexibility and accuracy

ğŸ§® Feature Importance from Coefficients
â†’ Identify which variables influence the outcome most

ğŸ§ª Compare Solvers (liblinear, saga, lbfgs)
â†’ Analyze solver impact on model performance

ğŸ”¹ Data Engineering
ğŸš¢ Titanic Dataset Case Study

Handle missing values

Encode categorical features

Apply logistic regression and evaluate performance

âš™ï¸ Feature Scaling (StandardScaler)

Train models on raw and standardized data

Compare accuracy

ğŸ’¾ Model Persistence
ğŸ’½ Save and Load Model using joblib

Save trained model to .pkl

Load model and make new predictions

ğŸ› ï¸ Tools & Libraries
pandas, numpy â€“ Data manipulation

scikit-learn â€“ Modeling, evaluation, tuning

matplotlib, seaborn â€“ Visualization

joblib â€“ Model serialization

imbalanced-learn â€“ Optional for imbalanced datasets
